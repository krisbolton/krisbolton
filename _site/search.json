[
  
    {
      "title"    : "3D Maps with Satellite Imagery in R",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/3D-maps-with-satellite-imagery-in-r'>3D Maps with Satellite Imagery in R<i class='ion ion-md-arrow-round-forward'></i></a> </h2> <div class='article__meta'> <time class='article__date' datetime='2020-04-29T16:00:00+01:00'>29 April 2020</time> – <span class='article__minutes'>8min read</span> </div><p class='article__excerpt'>Ths is my first foray into geographic information systems (GIS) and 3D map visualization. I was inspired by a post and tutorial by Tyler Morgan-Wall, a physicist and data scientist from the US...</p><div class='article__bottom'><div class='article-tags__box'><a href='/tag/tutorials' class='article__tag'>tutorials</a><a href='/tag/GIS' class='article__tag'>GIS</a><a href='/tag/R' class='article__tag'>R</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "tutorials, GIS, and R",
      "url"      : "/3D-maps-with-satellite-imagery-in-r",
      "date"     : "2020-04-29 16:00:00 +0100",
      "content"  : "Ths is my first foray into geographic information systems (GIS) and 3D map visualization. I was inspired by a post and tutorial by Tyler Morgan-Wall, a physicist and data scientist from the US. I delved into R breifly back undergrad out of general interest, however you don’t need to have used R before to follow these or Tyler’s steps.I’ve written up my experience, as it differs a little from the steps laid out in his blog post tutorial, as I didn’t have most of the R packages installed and I ran into a few issues. I went through Tyler’s tutorial twice, once on my macbook and again on Windows I was attempting to gain faster render times for the final product, so the following will work on Windows and Mac. If you’re even mildly interested in visualizing maps in 3D or R programming check out Tyler’s blog.Installing RInstall R, R Studio an IDE for R and XQuartz in addition if you’re on Mac.Visualizing The CuillinWe’re going to visualize The Cuillin, a range of mountains which are part of the Isle of Skye, Scotland. The area has featured in movies, such as Prometheus due to its ailen-world visuals and general stunning beauty. I was hoping to produce imagery as visually appealing as Tyler Morgan-Wall’s render of Zion National Park, sadly, my render doesn’t appear as detailed and it’s quite dark. But, I managed to create a 3D render of the selected area, so I can’t complain. I’ll investigate making it look prettier another time.Getting the DataYou will need to make an account to gather the data you need at USGS. If at any point you’re greeted with the requirement for a password when downloading data, you need to make an account with the data owner.Elevation DataOnce you have your account, head over to 30-Meter SRTM Tile Downloader, a website which makes finding the data you want much easier. The USGS website lists the data in a never ending series of N00E072.htg.zip, buried in a series of folders with names you don’t understand. The tile downloader provides a map of earth overlaid with tiles of the respective 30-meter resolution elevation data.Select and download the area of the data you want. If the area overlaps more than one square, that’s fine we can merge the data sets in R.Satellite ImageryOn the USGS Earth Explorer navigate to the Isle of Skye, sticking out at the north western edge of Scotland, shielded by the Outer Hebrides.Click ‘Use Map’ on the side pannel on the left, this will add a red bounding box around the edge of the area you are viewing.On the Data Sets tab on the left pannel, select Landsat &gt; Landsat Collection 1 Level-1 &gt; Landsat 8 OLI/TIRS C1 Level-1, and click results at the bottom.This will search the area you selected a few moments ago for availalbe imagery. Now you just have to find a picture. At the time I was using the application a suitable picture was number 4 on the list. Be careful not to choose an image full of cloud.Download the TIF file of the image you want. This will be quite large (~850MB), but it includes seperate image RGB channels which we’ll be using later.The CodeThe following code is simply the code from Tyler Morgan-Wall’s blog post (under MIT license) on the subject. I considered cutting it down, but that would rob the reader of the step-by-step nature of Tyler’s metholody, and its helpful to see each step in turn. I added additional libraries which are required, and I changed the name of the variables to correspond to the different location (Isle of Skye).If you want to create imagery as visually appealing as his, you can copy &amp; paste the libraries below, and then follow his steps from the top. That was the consistent issue I faced as code ran, along with the multi-program initial set up.Install packagesOpen R Studio and create a new R script (File &gt; New File &gt; R Script). Add the following libraries which will be installed at runtime.library(rayshader)library(sp)library(raster)library(scales)library(magrittr)library(rgdal)library(magick)Add the datasets, and mergeLet’s load the elevation data, merge the two datasets into skye_elevation, plot height using the data and render the map. Move the downloaded hgt files into a folder somewhere and replace the file paths below with your own. If you don’t need to merge datasets simply remove the second line and replace assignment of skye_elevation to elevation1 (skye_elevation = elevation1), this just means you don’t need to replace that variable multiple places in the code, its not good code.elevation1 = raster::raster("C:/Users/USER/Documents/Dev/N57W006.hgt")elevation2 = raster::raster("C:/Users/USER/Documents/Dev/N57W007.hgt")skye_elevation = raster::merge(elevation1,elevation2)height_shade(raster_to_matrix(skye_elevation)) %&gt;%  plot_map()Open the plots tab in R Studio (bottom right). Our first output. Nice! It shows a heat-map of the elevation of the area.Now we’ll load the RGB (Red, Green, Blue) channels from the TIF zipped folder we downloaded earlier, these will be combined to make our satellite image. The folder will need unzipping and a folder created from that will need unzipping on Windows, Mac is one upzip. The TIF files ending B4, B3, B2 are the reg, green and blue channels respectively. You can delete the other files to save some space.skye_r = raster::raster("C:/Users/USER/Documents/Dev/B4.TIF")skye_g = raster::raster("C:/Users/USER/Documents/Dev/B3.TIF")skye_b = raster::raster("C:/Users/USER/Documents/Dev/B2.TIF")skye_rbg = raster::stack(skye_r, skye_g, skye_b)raster::plotRGB(skye_rbg, scale=255^2)As Tyler points out, this is a little dark. We need to apply gamma:skye_rbg_corrected = sqrt(raster::stack(skye_r, skye_g, skye_b))raster::plotRGB(skye_rbg_corrected)That’s better, if a little washed-out. We’ll add contrast later to fix that.raster::crs(skye_r)raster::crs(skye_elevation)crs(skye_r)The above reveals a problem, the coordinate systems for elevation and the image data aren’t of the same type. We fix this by transforming the elevation data to UTM coordinates using raster::projectRaster() and store it in skye_elevation_utm.skye_elevation_utm = raster::projectRaster(skye_elevation, crs = crs(skye_r), method = "bilinear")crs(skye_elevation_utm)Now we’ll crop the data to a desired area, we’re going to focus on the Cuillin mountain range in the south of Skye. Head back to the USGS Earth Explorer, where you obtained the satellite imagary and find the appropraite bottom left and top right longditude and latitude coordinates to crop to. You may encounter errors which indicate you’re cropping an area not within the bounds of the data, or which indicate you’ve entered the long/lat incorrectly - somehow when typing I managed to reverse x/y.bottom_left = c(y=-6.3460, x=57.1407)top_right   = c(y=-6.0081, x=57.3299)extent_latlong = sp::SpatialPoints(rbind(bottom_left, top_right), proj4string=sp::CRS("+proj=longlat +ellps=WGS84 +datum=WGS84"))extent_utm = sp::spTransform(extent_latlong, raster::crs(skye_elevation_utm))e = raster::extent(extent_utm)eBelow we crop the datasets, create an array containing the RGB values and convert the elevation data to an R matrix, which is what the rayshader function expects.skye_rgb_cropped = raster::crop(skye_rbg_corrected, e)elevation_cropped = raster::crop(skye_elevation_utm, e)names(skye_rgb_cropped) = c("r","g","b")skye_r_cropped = rayshader::raster_to_matrix(skye_rgb_cropped$r)skye_g_cropped = rayshader::raster_to_matrix(skye_rgb_cropped$g)skye_b_cropped = rayshader::raster_to_matrix(skye_rgb_cropped$b)zionel_matrix = rayshader::raster_to_matrix(elevation_cropped)skye_rgb_array = array(0,dim=c(nrow(skye_r_cropped),ncol(skye_r_cropped),3))skye_rgb_array[,,1] = skye_r_cropped/255 #Red layerskye_rgb_array[,,2] = skye_g_cropped/255 #Blue layerskye_rgb_array[,,3] = skye_b_cropped/255 #Green layerskye_rgb_array = aperm(skye_rgb_array, c(2,1,3))plot_map(skye_rgb_array)We increase the contrast using the scales::rescale() function and generate our image.skye_rgb_contrast = scales::rescale(skye_rgb_array,to=c(0,1))plot_map(skye_rgb_contrast)Looking pretty good. Not as vibrant and appealing as Tyle’s, but it’s a first try.Now for the bit you’re doing this for, the 3D render of the location:plot_3d(skye_rgb_contrast, zionel_matrix, windowsize = c(1100,900), zscale = 15, shadowdepth = -50,        zoom=0.5, phi=45,theta=-45,fov=70, background = "#F2E1D0", shadowcolor = "#523E2B")render_snapshot(title_text = "The Cuillin, Isle of Skye, Scotland | Imagery: Landsat 8 | DEM: 30m SRTM",                title_bar_color = "#1f5214", title_color = "white", title_bar_alpha = 1)This can be finiky on Windows, you might not be albe to access the x icon to close the window which is created, but resizing the window by draging pops the window top down into view. I’m likely missing a function or parameter I’m unaware of, or its a bug.The Final ResultWoohoo! 3D maps.Tyler goes a step further to create a rotating video. It took around 20 minutes for me to render, despite a i7-5820K - although R is single threaded by default. I went down a rabbithole learning about paralell processing in R, so I’m looking to reduce that time as once I’ve figured out how to make the images look better. I’d like to render some interesting locations and add the images to Wikipedia.Hope you enjoyed the write up. See you again next time."
    } ,
  
    {
      "title"    : "Experimenting with the Modern Honeypot Network (MHN)",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/experimenting-with-the-modern-honeypot-network'>Experimenting with the Modern Honeypot Network (MHN)<i class='ion ion-md-arrow-round-forward'></i></a> </h2> <div class='article__meta'> <time class='article__date' datetime='2020-04-22T16:00:00+01:00'>22 April 2020</time> – <span class='article__minutes'>4min read</span> </div><p class='article__excerpt'>MHN is an open-source centralized server for managing honeypots, making deployment and data collection simple and fast. My goal was to collect malware and aggregate statistics....</p><div class='article__bottom'><div class='article-tags__box'><a href='/tag/honeypot' class='article__tag'>honeypot</a><a href='/tag/malware' class='article__tag'>malware</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "honeypot and malware",
      "url"      : "/experimenting-with-the-modern-honeypot-network",
      "date"     : "2020-04-22 16:00:00 +0100",
      "content"  : "MHN is an open-source centralized server for managing honeypots, making deployment and data collection simple and fast. MHN currently supports a number of honeypot types, check out the list of supported sensors for details, they also allow adding new sensors should you wish.SetupMy goal was to collect malware and aggregate statistics on various connections and attacks against a single sensor server I deployed. The architecture was two nano linode ubuntu 16.04 instances, one acting as the server and the other as the sensor. This turned out well, the nano instance was enough to handle the workload the majority of the time.Server setupFind a server provider, I chose Linode. I went with the nano configuration; 1GB RAM, 1CPU, 25GB storage, 1TB bandwidth for $5 per month. Enough for a small setup, as you add sensors the server will need more resources, so provision accordingly.Give your server a descriptive name, e.g. “mhn-server”. Ubuntu 16.04 is recommended by MHN as its been tested and verified to work with MHN.Secure the mhn-server as your normally would, its intended for you to manage sensors, you’re not looking for attackers to attack this instance.Server stepsCreate a non-root user.adduser deployDon’t install MHN as root, it will not work as intended.Add deploy as sudo user under ‘user privilege specification’:visudodeploy ALL=(ALL:ALL) ALLSwitch to the deploy user:su deployClone the MHN GitHub repo:git clone https://github.com/pwnlandia/mhn.gitChange to the mhn directory:cd mhnRun the installation script:sudo ./install.shTowards the end of the installation you’ll be asked a series of questions. I chose no debug mode, I added a new gmail I created - this will also be used to login to the web interface. I didn’t need splunk or ELK. I left the rest of the options as default.Login to the web interface.ipconfigCopy &amp; paste the IP into a browser on your machine, and login with the email and password you provided earlier.The server’s done!Sensor setupCreate a second instance on your service provider, again using a descriptive name - this helps if you scale things up later. I went with ‘mhn-snort-dionaea’.Snort is an intrusion detection system (IDS), which will provide detail on attacks against the server. It can be configured extensively, see the snort documentation for more.Dionaea is a a honeypot emulating various network services to capture malware. See the dionaea documentation for specific configuration details.Sensor stepsSelect a scriptIn the web interface provided by the mhn-server, go to the deploy tab and chose the sensor you want to deploy from the ‘select script’ drop down menu.Copy &amp; paste wget stringSensor setup is as easy as copy &amp; pasting the wget command string into the sensor instance.Check the sensors tabClick the sensors tab in the web interface to view your new sensor.DionaeaFollow the same steps copy &amp; pasting the wget script string for dionaea into the mhn-snort-dionaea instance.Now you have snort and dionaea setup and running. You can view incoming attacks in the web interface.Collecting dataAs mentioned towards the beginning, my intention was to gather aggregate statistics and hopefully some malware files. Your goals may be different and you can add different sensors and service configurations to achieve your goals.Immediately, I saw a small number of attacks coming in, surprising how quickly your services are found.Within 24 hours I had logged over 300,000 scans and attacks from across the world. The web interface provides an enticing global attack map (below). The yellow dot shows the location of the server and the red dots show attacker locations.The sensor CPU handled the incoming traffic well, utilising around 40% max (observed). As scans/attacks increase between approx. 08:00 and 11:50 I turn on ufw, the linux firewall, to observe the effect out of interest. This is why the graph shows connections and CPU suddenly drop.Later I turned the firewall off and resumed data collection.I’m planning on putting together a more detailed post of the data I captured. It won’t be anything particularly special, mostly data on which ports were most attacked, perhaps hints at attack behaviour. Dionaea did capture some files, but I’ve yet to take a look.ReminderWhenever you do anything with malware consider the legal implications. Here you are collecting malware - likely a legal activity within your country. However, this quickly changes should you distribute it. Setting the server to be publicly available so you can download the malware, for example. To be clear, this is not legal advice, I am not a legal expert. As ever, seek advice specific to your location and proceed with caution."
    } ,
  
    {
      "title"    : "UK Cyber Security Spending Data 2018",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/uk-cyber-security-spending'>UK Cyber Security Spending Data 2018<i class='ion ion-md-arrow-round-forward'></i></a> </h2> <div class='article__meta'> <time class='article__date' datetime='2019-03-10T15:00:00+00:00'>10 March 2019</time> – <span class='article__minutes'>3min read</span> </div><p class='article__excerpt'>In late 2018 I started sending Freedom of Information Requests (FOI) to various UK Government Departments, Agencies and Non-Governmental Bodies asking them to disclose yearly spending...</p><div class='article__bottom'><div class='article-tags__box'><a href='/tag/Research' class='article__tag'>Research</a><a href='/tag/Projects' class='article__tag'>Projects</a><a href='/tag/Data' class='article__tag'>Data</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "Research, Projects, and Data",
      "url"      : "/uk-cyber-security-spending",
      "date"     : "2019-03-10 15:00:00 +0000",
      "content"  : "In late 2018 I started sending Freedom of Information Requests (FOI) to various UK Government Departments, Agencies and Non-Governmental Bodies asking them to disclose their yearly spending data on cyber security.My assertion is cyber security spending is an indication of the overall security of an organiation and how seriously they take security.Initially I started with services which can be considered of naitonal importance, and the lack of security could be considered a risk to national security. This post will briefly dicuss the responses of UK national ambulance services from Northern Ireland, Scotland, Wales and England.The FOI RequestEach Department, Agency or Non-Governmental Body was asked to provide the same information:  Provide the total amount of money spent on Cyber Security for financial years 2015-18.  The term “Cyber Security” is defined as: “… consider the term to encompass activities relating to information security, computer security and computer network security. Including staff training, consultant services, software and hardware.”  Additionaly, “Details on what training and consultant services were for …”At the time of the request (December 2018) this would provide approximately three years of data.All of the information I collect and the exact request wording is available on GitHub.Status of ResquestsThe Results So FarI haven’t finished recieving the data from some of the ambulance services, notably the West Midlands and South Central - they’re overdue. I’ll be following up soon. Additionally, due to the structure of some of the services, namely the three remote island services; Guernsey, Isle of Man and States of Jersey, I have found it difficult to contact the appropraite people. Eventually this will be complete.It must be pointed out I am not a statistician, and as different entities do not record or store financial data in the same way this make analysis difficult.OK! On to some results.It is clear there is a large disparity between the spending of some abulance services compared to others. Excluding outliers, and focusing on a particular category, Network Security for example, and the financial year 2016/7, East Midlands spent £1,275, North East Ambulance spent £4,175 and the Welsh service spent £46,947.East Midlands Ambulance Service spends significantly different amounts per year, although the default appears to be very low - they did not specificy details so it is difficult to analyse. In 2015 and 2018 they spend over £100,000, while 2016 and 2017 they spent a mere £1,275 each year.The North East Ambulance Service is consistent in its spending on Network Security over the year period that they provided data. In 2015 and 2016 they spent £4,175 and £4,000 in 2018. While in 2017 they spent £57,375, the increase was indicated as capital expenditure on improvements in perimeter security.The Welsh Ambulance Service is somewhat similar to East Midlands, although there is perhaps a trend towards higher spend after WannaCry(?). They spent £5,337 in 2015/6, and £46,793 and £54,727 in 2016/7 and 2017/8 respectively.It is difficult to analyse due to the lack of insight into how they are actually spending the money. However, it isn’t possible to obtain this data due to the security risk of providing detailed explanations of such spending. I purposefully suggested recipients do not include specifics for this reason.It’s going to be an interesting project once it is complete. I also intend to collect data from the other services; police and fire. As well as Government Departments.Keep an eye on the GitHub for regular updates, or check back here in a month or two.Update 2020: This project is closed. Data collected is still available in the GitHub repo mentioned above. At some point I would like to do this project again with new data and complete the FOI requests to all the services and departments."
    } ,
  
    {
      "title"    : "A Practical Introduction to Neural Networks with Python",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/a-practical-introduction-to-artificial-neural-networks-with-python'>A Practical Introduction to Neural Networks with Python<i class='ion ion-md-arrow-round-forward'></i></a> </h2> <div class='article__meta'> <time class='article__date' datetime='2018-08-22T16:00:00+01:00'>22 August 2018</time> – <span class='article__minutes'>19min read</span> </div><p class='article__excerpt'>Neural networks are adept at recognising patterns, this is pattern recognition is the reason they have become so widely used and talked about in recent years...</p><div class='article__bottom'><div class='article-tags__box'><a href='/tag/machine learning' class='article__tag'>machine learning</a><a href='/tag/neural networks' class='article__tag'>neural networks</a><a href='/tag/tutorials' class='article__tag'>tutorials</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "machine learning, neural networks, and tutorials",
      "url"      : "/a-practical-introduction-to-artificial-neural-networks-with-python",
      "date"     : "2018-08-22 16:00:00 +0100",
      "content"  : "Update: Since 2018 I have created better resources for those interested in machine learning. Head over to this course on mahcine learning which covers neural networks.An Introduction to Artificial Neural NetworksArtificial neurons mimic the basic function of biological neurons, and much like their biological counterparts they only become useful when connected in a larger network, called Artificial Neural Networks. Neural networks may mimic the basic building block of the human brain, however, when connected to a larger network artificial neurons do not inherit their biological counterparts ability of what is termed “general intelligence”. Even the largest collection of artificial neurons are not intelligent. Artificial Neural Networks are only capable of performing specific tasks.Neural networks are adept at recognising patterns, this is pattern recognition is the reason they have become so widely used and talked about in recent years. The ability of neural networks to discover and recognise patterns allows them to far surpass traditional methods in computer science, making them viable for use in research and business.This pattern recognition ability can be used to solve a wide variety of problems. One of the projects in the latter half of this book uses sentiment analysis, a natural language processing categorisation problem. Is a string of text positive, neutral or negative? This question may seem simple at first, however, the algorithm will have to traverse the nuances in human speech; sarcasm and other complex linguistic nuances can blur the question for machines. Despite this, neural networks can achieve greater than 70% accuracy, and the most advanced neural networks can achieve above 80% in sentiment analysis and opinion mining tasks. This is more than enough to provide advantages over using humans to categorise sentiment.An Artificial NeuronThe image below shows an illustration of a single biological neuron annotated to describe a single artificial neurons function.A biological neuron receives input signals from its dendrites from other neurons and sends output signals along its axon, which branches out and connects to other neurons. In the illustration above, the input signal is represented by x0, as this signal ‘travels’ it is multiplied (w0 x0) based on the weight variable (w0). The weight variables are learnable and the weights strength and polarity (positive or negative) control the influence of the signal. The influence is determined by summing the signal input and weight (∑i wi xi + b) which is then calculated by the activation function f, if it is above a certain threshold the neuron fires. Below is a simplified diagram.SigmaThe Greek letter sigma ∑ is used to represent summation, this can be thought of as analogous to a  for loop in programming.Types of Artificial NeuronWe’ve hinted at the existence of different types of neurons which serve different purposes. In this section we will discuss the different types of neuron which will make up a neural network. Networks don’t have to have every type of neuron, and some neurons can have multiple purposes.Neuron naming conventions differ between sources, industries, and people of different backgrounds. Neurons might also be known as units or nodes. They’re simply different names for the same thing.Input and Output NeuronsInput and output neurons can be thought of as placeholders which represent information passed into the network and information processed out from the network in the form of vectors or arrays. These vectors typically contain floating point numbers. The number of elements within the vector is equal to the number of input neurons.Hidden NeuronsHidden neurons sit in the middle of a network, surrounded by other neurons – they receive input from input neurons or other hidden neurons, and they output to output neurons or hidden neurons. They are never connected to the data or produce output themselves. This is their defining characteristic.Bias NeuronsThe addition of bias into a network helps the network learn by allowing the programmer to shift the activation function curve to the left or right, the fine tuning of this parameter can affect the success of learning. Below is an example of a network including bias neurons.The diagram shows a neural network designed to compute XOR arguments. Each layer, excluding the input layer, has a bias neuron attached. Later on in this chapter we will build and calculate the output of this network, and build an example in scikit-learn.An example of how a programmer can shift the activation function laterally:Context NeuronsContext neurons exist in some specific types of neural networks and are not present in all network types. For example, Recurrent neural networks use context neurons as a form of memory to hold on to information from past calculations. They attempt to mimic context created by biological phenomena within human brains. An analogy helps make their purpose clearer; if you’re crossing the street and you hear a car horn you will likely stop and look towards the noise, looking for danger. However, if you were at a sports event and hear a horn from an over enthusiastic supporter you ignore it. You’ve learned loud noises are important when crossing the street, but are meaningless within other contexts.Below is an example of a recurrent neural network architecture:The network resembles a typical network, with input I1, two hidden neurons and output O1. Additionally, information is duplicated and sent to C1 and C2 which provide data from previous calculations.WeightWeight variables allow the network or programmer to adjust the program to closer match the desired output. Weights are programmatically manipulated by the network during training iterations to bring the error rate down as the network learns. As seen in the section discussing bias, bias allows the manipulation of the activation function left or right on a graph. Weight allows the gradient of the activation function to be manipulated.Activation Functions in BriefThe frequency of the firing of an artificial neuron is determined by an activation function. It determines at what threshold the neuron will fire. This section describes the Sigmoid activation function to bring clarity to the operation of an artificial neuron. Activation functions will be discussed in detail further on in this section.The graph above shows the Sigmoid activation function, which will convert all input signals into positive values between 0 and 1. The use of other activation functions with wider values, or negative values change the frequency of the firing of a neuron and will suit different types of data and purposes.Practical ExerciseThe PerceptronThe foundation of modern neural networks was created in 1956 by Frank Rosenblatt and sort to mimic the architecture of a basic biological neuron, it was called a perceptron. This architecture can be seen in the illustration at the beginning of this chapter.Classifying flowersScikit-learn includes the Iris flower dataset which is often used for algorithm testing purposes, and it has become somewhat of a “hello world” dataset of neural networks. The aim of our single layer model is to classify flowers from the Iris dataset into different categories.Installing Scikit-learn via AnacondaI recommend installing Anaconda, a scientific python library which includes scikit-learn, all of its dependencies, matlibplot and more. We’ll be using jupyter notebook, formally IPython Notebook, bundled with Anaconda to run our code.https://www.anaconda.com/downloadIf you’re having trouble please refer to the scikit-learn or anaconda documentation. Or if conflicts are possible with your existing installations, consider using a virtual machine and start from a clean slate.Jupyter NotebookLaunch jupyter notebook via the Anaconda Navigator application, which was installed with Anaconda.Create a new Python notebook in the jupyter web interface which has launched.Now we can write python and run it live in the web interface.Importing Dependenciesfrom sklearn import datasetsfrom sklearn.preprocessing import StandardScalerfrom sklearn.linear_model import Perceptronfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import accuracy_scorefrom matplotlib.pyplot as pltThe Iris Data SetThe Iris dataset consists of 150 samples of four features per sample, measuring the length and width of sepals and petals (in cm), with 50 samples for three species of Iris (Iris setosa, Iris virginica, and Iris versicolor). First featured in British statistician and biologist Ronald Fisher’s research article in 1936 the data set has become a popular test of predictive algorithms, including neural networks.The Iris dataset is small in comparison to the data sets which are needed for more complex algorithms, for example, in deep learning convolutional neural networks require tens of thousands of data points to learn effectively.Itallics indicate comments or text output by the console.#Load the Iris datasetiris = datasets.load_iris()#Assign the data to verticesx = iris.datay = iris.targetLet’s take a look at the data we’re going to manipulate.x indicies:#Print the first five features (the four measurements in a 2D array)x[:5]Output:array([[5.1, 3.5, 1.4, 0.2],       [4.9, 3. , 1.4, 0.2],       [4.7, 3.2, 1.3, 0.2],       [4.6, 3.1, 1.5, 0.2],       [5. , 3.6, 1.4, 0.2]])y indicies:#Print all 150 indices of x axis (the class of each sample)y[:150]Output:array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])Neural Networks require the data to be represented as floating point numbers. This allows the decimal points high accuracy to be used by the various calculations within the underlying implementation. Floating point numbers can simply represent data with finer granularity than the ten representations that integers allow. This can be appreciated by looking at the annotated neuron illustration at the start of this section.The 2D array held in x represents four columns: Sepal Length, Sepal Width, Petal Length and Petal Width.Visualising the Data SetNow let’s visualise the data set to get a better idea of what the dataset actually describes.#Import datasetiris = datasets.load_iris()X = iris.datay = iris.targetplt.figure(2, figsize=(8, 6))plt.clf()#Plot graphplt.scatter(X[:, 0], X[:, 1], c=y, cmap=plt.cm.Set1, edgecolor='k')plt.xlabel('Sepal length')plt.ylabel('Sepal width')plt.xticks(())plt.yticks(())plt.show()This graph shows the distribution of the three sample types, categorized by two of the features, sepal width and sepal length. Feel free to change the code and visualise the data in different ways.Preparing the DataWe need to set aside some of the data set to become the data the perceptron is trained on. This data isn’t used again once the training is complete – the algorithm has already seen and learned from this information, and would serve no purpose to be classified – as the answer is already known.#Set aside 30% of the data set for trainingx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3)The StandardScaler() function standardised all of the features in a dataset to have a mean of zero and unit variance, to ensure all of the features are distributed normally. Many predictive algorithms require the data set to be standardised otherwise their behavior will be unpredictable.#Train the scaler, which standarises all the features to have mean of zero and unit variancesc = StandardScaler()sc.fit(x_train)Now we apply the scaler to each section of the split data set.#Apply the scaler to the X training datax_train_std = sc.transform(x_train)#Apply the SAME scaler to the X test datax_test_std = sc.transform(x_test)Scikit-Learn PerceptronHere we use the Perceptron() function to invoke a perceptron object with the following parameters:max_iter is set to a maximum of 50 iterations over the data set, iterations are also referred to as epochs. Remember this word for if you plan to read further texts, it can be confusing having words used interchangeably.eta0 is a constant value by which updates are multiplied. This will ensure the values change and don’t stagnate, it can be thought of as the bias.verbose is a boolean flag, when set to 1 it will print information for each epoch.#Create a perceptron object with 50 iterations over the data set, and a learning rate of 0.3ppn = Perceptron(max_iter=50, eta0=1, verbose=0)#Train the perceptronppn.fit(x_train_std, y_train)Perceptron(alpha=0.0001, class_weight=None, eta0=1, fit_intercept=True,      max_iter=50, n_iter=None, n_jobs=1, penalty=None, random_state=0,      shuffle=True, tol=None, verbose=0, warm_start=False)#Apply the trained perceptron on the X data to make predicts for the y test datay_pred = ppn.predict(x_test_std)The Results#Print the predicted y test datay_predarray([1, 2, 2, 1, 1, 0, 2, 2, 1, 2, 2, 0, 2, 1, 1, 2, 1, 0, 0, 1, 2, 1,       2, 2, 1, 1, 0, 2, 2, 2, 0, 1, 1, 0, 0, 1, 1, 1, 2, 2, 0, 1, 1, 1,       1])#Print the true y test datay_testarray([1, 2, 2, 1, 1, 0, 2, 1, 1, 2, 2, 0, 2, 1, 1, 2, 1, 0, 0, 1, 2, 0,       2, 2, 0, 1, 0, 2, 2, 2, 0, 1, 1, 0, 0, 1, 0, 1, 2, 2, 0, 1, 0, 1,       1])#Print the accuracy of the implementationprint('Accuracy: %.2f' % accuracy_score(y_test, y_pred))Accuracy: 0.89This implementation of the most simple neural network achieves high accuracy. Throughout multiple runs it achieved between 0.89 and 1.00 accuracy, or said another way it’s 89% to 100% accurate.This was achieved following the recommended parameter settings found in the scikit-learn documentation. However, trial and error manipulation of the parameters can be an important method in machine learning, so don’t be afraid to experiment. Always consider how the parameters are being used internally, how they affect the data and experiment to see how changing them actually affects the result.Try changing the parameters for yourself to see how that affects the accuracy. See the scikit-learn perceptron documentation to see other parameters which you can manipulate. Hyperparameter manipulation is an important part of tuning and getting the best out of neural network implementations, as you read through the chapters of this book you will learn more about different parameters and continue to try your hand at practical exercises. Tuning is also discussed in detail in the Tuning and Evaluating Neural Networks chapter.Under the Hood: The Scikit-Learn PerceptronProgramming libraries are created to make the programmers life as easy as possible by providing commonly needed applications written by others. With this as their main aim libraries may not implement algorithms straight from textbooks. Additionally, as libraries are created with modularity in mind, their underlying implementation will likely be more complex than expected.Scikit-learn’s perceptron is no different. The Perceptron() function shares the underlying implementation of the SGDClassifier() function, and its functionality differs from traditional simple perceptrons as a result. For example, traditionally perceptrons required data to be linearly separable, that is to be able to be separated cleanly without overlap – imagine a graph with a single line separating two distinct groups of data points on each side.SGDClassifier() implements regularized linear models utilizing the stochastic gradient descent (SGD) learning algorithm. SGDClassifier(loss=“perceptron”, eta0=1, learning_rate=“constant”, penalty=None) is equivalent to Perceptron().Jargon BusterThat last bit became a little complicated, so lets break it down. “SGDClassifier() implements regularized linear models utilizing the stochastic gradient descent (SGD) learning algorithm”Regularized by adding a penalty to the loss function that reduces the model parameters towards the zero vector, 0.0 on a graph, using one of two methods L1 or L2. Regularization increases the efficiency of the network. This will be discussed more in the chapter on Training Neural Networks.Linear model, referring to a type of classifier model which defines categories based on the linear combination of a features characteristics. That is a mathematical expression created by multiplying a set of characteristics by a constant and summing the result. X1 w1 + bStochastic Gradient Descent (SGD) is a type of backpropagation learning algorithm that calculates gradients based on the values of a batch with the aim of reducing the gradient (imagine a graph with a steadily decreasing learning rate gradient), hence gradient descent. The algorithm splits the data into batches and the gradients are summed and weights updated, similar to backpropagation.If you enjoyed this practical introduction you may be interested in my updated and more detailed course on machine learning for security."
    } ,
  
    {
      "title"    : "Why You Should get into Machine Mearning",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/why-you-should-get-into-machine-learning'>Why You Should get into Machine Mearning<i class='ion ion-md-arrow-round-forward'></i></a> </h2> <div class='article__meta'> <time class='article__date' datetime='2018-07-26T16:00:00+01:00'>26 July 2018</time> – <span class='article__minutes'>5min read</span> </div><p class='article__excerpt'>Since 2006 the machine learning field has been growing at an unprecedented pace. New developments each year push growth upwards and it shows no signs of slowing...</p><div class='article__bottom'><div class='article-tags__box'><a href='/tag/machine learning' class='article__tag'>machine learning</a><a href='/tag/notes' class='article__tag'>notes</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "machine learning and notes",
      "url"      : "/why-you-should-get-into-machine-learning",
      "date"     : "2018-07-26 16:00:00 +0100",
      "content"  : "Four of the top ten and the two highest growth jobs are machine learning related according to LinkedIn.GrowthSince 2006 the machine learning field has been growing at an unprecedented pace. New developments each year push growth upwards and it shows no signs of slowing. Machine Learning has capabilities unheard of in computer science, from the outside it seems very close to human level intellect. Sadly, this is not the case.However, machine learning techniques and methods are some of the most powerful created and provided the new state-of-the-art in most of the areas they are applied. This has further increased the growth as academics, individuals and businesses hear of the abilities of these techniques they want to apply them to new problems.Google Trends can provide anecdotal evidence of the growth of machine learning. Below is a graph produced by Google Trends using Machine Learning as a search term plotting the interest globally over the last five years.Further anecdotal evidence of growth can be seen analysing specific machine learning tools and libraries using Google Trends, “TensorFlow”, “learn TensorFlow”, “Scikit learn”, etc.Mergers and AcquisitionsThe value of machine learning has not been lost on major corporations in the technology sector. Google, Facebook, Apple have acquired and absorbed business focusing on machine learning into their various areas of their business to add functionality to their products.The timeline above shows the acquisitions of Google, Apple and Facebook since 2010. At first glance you can see the increased speed of acquisitions. Upon closer inspection, you will notice acquisitions relating to existing services, or new services which launched soon after the acquisition. Mergers and acquisitions are often shrouded in secrecy to protect commercially sensitive information, so it can be difficult to gain much insight into the transactions, however researching the companies listed can provide some interesting information. Others are more obvious.Siri, acquired by Apple in 2010, became the core of Apple’s mobile virtual assistant. Google has made a number of acquisitions to further its own virtual assistant, Banter and API.ai provide conversational AI and advanced natural language processing.CareerAs businesses increase the size of their machine learning workforce; forming new machine learning projects and attempt to keep up with competitors, an opportunity presents itself for the reader. According to research conducted by LinkedIn, Machine Learning positions occupy the top spots for the fastest growing jobs on LinkedIn.LinkedIn monitored the growth of users adding their current position in various fields and compared the results over five years (2013-2017) and compiled an ‘Emerging Jobs Report 2017’. The following are machine learning specific.Machine Learning Engineer 9.8X growth.Data Scientist 6.5X growth.Big Data Developer 5.5X growth.Director of Data Science 4.9X growth.Four of the top ten, and the two highest growth jobs in the report are machine learning related. Incidentally, another three are within the computing field making computing easily the fastest growing job sector on LinkedIn.Earning potential should also be considered. Salaries will not be discussed here, as they are highly dependant on location. However, the job intelligence websites Payscale and Glassdoor can provide an indication, or detailed stats on the earning potential of various jobs.ResourcesHardwareOne of the largest historical obstacles to machine learning progressing as a field was the limited availability and power of computing hardware. This is no longer the obstacle it used to be; the growth and advancement of computer hardware, specifically graphical processing units (GPUs), and the advent and growth of infrastructure as a service (IaaS) and platform as a service (PaaS).An unexpected accelerator of the computer hardware industry has been the cryptocurrency industry. In early 2018 enthusiastic crypto miners looking to make high profits created a global shortage of GPUs, causing some retailers to limit the number of cards individuals could purchase. During this GPU card shortage, industrial crypto miners started purchasing the processor wafer, the material CPUs/GPUs are made of, to create their own custom cards. In January 2017 the manufacturer TSMC were selling more 16nm wafer to crypto miners than nVidia.Ignoring what this means for the average consumer, I would argue the increased demand and revenue for card manufacturers and wafer manufacturers can only accelerate the creation of faster and more efficient hardware, which will become the backbone of future machine learning research and commercial endeavors.SoftwarePowerful open source machine learning software libraries have emerged over the last five years. The most popular of these machine learning libraries have come from powerhouses of computing such as Google, Facebook and Microsoft. Written by experts in their field, tested and used on real-world problems and programs within their origin company. And they’re available for you to use.TensorFlow is one such library. The most popular machine learning library on GitHub, created by Google’s Brain team and open sourced in 2015. A unique visual dashboard allows the visualisation of complex machine learning algorithms, and the user base numbers in the thousands and a number of informative and tutorial books have been released, so support is readily available. For these reasons, this book uses TensorFlow for a number of the projects in future chapters.ImpactMachine Learning is already having a positive impact on economies and the lives of the product users.Seize the opportunity.ReferencesGoogle Trends: machine Learning (2018). [Accesed July 2018]. https://trends.google.com/trends/explore?date=today%205-y&amp;q=Machine%20LearningCB Insights: The Race for AI (2018). [Accessed July 2018]. https://www.cbinsights.com/research/top-acquirers-ai-startups-ma-timelineLinkedIn: The Fastest Growing Jobs in the US (2018). [Accessed July 2018]. https://blog.linkedin.com/2017/december/7/the-fastest-growing-jobs-in-the-u-s-based-on-linkedin-dataLinkedIn: Emerging US Jobs Report 2017 (2018). [Accessed July 2018]. https://economicgraph.linkedin.com/research/LinkedIns-2017-US-Emerging-Jobs-ReportPC GAMES N: TSMC are currently selling more 16nm chips to cryptocurrency miners than Nvidia (2018). [Accessed July 2018]. https://www.pcgamesn.com/tsmc-bitcoin-supply-nvidiaDark Vision Hardware: Bitmain is buying 20k 16nm wafers from TSMC per month (2018). [Accessed July 2018]. https://www.dvhardware.net/article68109.html"
    } ,
  
    {
      "title"    : "A Quick Introduction to Artificial Neural Networks (Part 2)",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/a-quick-introduction-to-artificial-neural-networks-part-2'>A Quick Introduction to Artificial Neural Networks (Part 2)<i class='ion ion-md-arrow-round-forward'></i></a> </h2> <div class='article__meta'> <time class='article__date' datetime='2018-06-05T16:00:00+01:00'>05 June 2018</time> – <span class='article__minutes'>3min read</span> </div><p class='article__excerpt'>This part will discuss activation functions. Activation functions set a threshold which determines the frequency at which artificial neurons fire (their output). In biological neurons...</p><div class='article__bottom'><div class='article-tags__box'><a href='/tag/machine learning' class='article__tag'>machine learning</a><a href='/tag/neural networks' class='article__tag'>neural networks</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "machine learning and neural networks",
      "url"      : "/a-quick-introduction-to-artificial-neural-networks-part-2",
      "date"     : "2018-06-05 16:00:00 +0100",
      "content"  : "Update: Since 2018 I have created better resources for those interested in machine learning. Head over to this course on mahcine learning which covers neural networks.Activation FunctionsIn part one of this Quick Introduction to Artificial Neural Networks we examined a diagram of a neural network. This part will discuss activation functions. Activation functions set a threshold which determines the frequency at which artificial neurons fire (their output). In biological neurons the precise timing of the neuron firing conveys information, in artificial neurons only the frequency is important.Linear Activation FunctionThe linear activation function simply returns the neuron input value as its output value, without manipulating it at all. This type of activation function is often used where regression is to be applied, and the network is to learn to output numeric values. For example, modelling linear regression, a statistical technique for determining the relationship between values.Step Activation FunctionThe step activation function only output two values based on input, 0 or 1. If the input value is below 0.5 the returned value is 0, if the input value is 0.5 or above the returned value is 1. This allows the mapping of boolean values, true and false.Sigmoid Activation FunctionThe Sigmoid activation function compresses input values to values between 0 and 1.0.Hyperbolic Tangent Activation FunctionThe Hyperbolic Tangent activation function, also called the tanh activation function conforms input signals to values between -1.0 and 1.0. It is similar to the Sigmoid activation function, with the additional value range of 0 to -1.0.This additional range proves useful when the input values to the network are negative. In such circumstances the Sigmoid function reduces such negative values to near 0, which results in the networks parameters being updated less regularly and negatively affecting training. The Tanh function does not suffer this same flaw, as negative values are not forced into a positive range.Rectified Linear Units (ReLU)The Rectified Linear Units (ReLU) activation function does not compress values to a small range like the Sigmoid or Tanh activation functions, which compress input values to 0 to 1, or -1 to 1.0 respectively. The increased range offered by ReLU results in far superior performance in training compared to both Sigmoid and Tanh.Softmax Activation FunctionThe Softmax activation function compresses values to positive values between 0.0 and 1.0. Typically placed in output layers of networks used for classification, the Softmax neurons allow the prediction of outputs to certain classes.SummaryIt can be difficult to grasp the usefulness of the different activation functions, at first glance they all look the very similar. Further, how do you decide between them? Luckily, there are best practices and established use-cases. For example, the Softmax activation function is usually found in the output layer of a classification network, the Softmax neuron with the highest value dictates the predicted class of the input value – remember that the neurons have been trained and thus it can be said that the neurons belong to certain classes as decided by the training."
    } ,
  
    {
      "title"    : "A Quick Introduction to Artificial Neural Networks (Part 1)",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/a-quick-introduction-to-artificial-neural-networks-part-1'>A Quick Introduction to Artificial Neural Networks (Part 1)<i class='ion ion-md-arrow-round-forward'></i></a> </h2> <div class='article__meta'> <time class='article__date' datetime='2018-04-09T16:01:35+01:00'>09 April 2018</time> – <span class='article__minutes'>2min read</span> </div><p class='article__excerpt'>Artificial neurons mimic the basic function of biological neurons, and much like their biological counterparts they only become useful when connected in a larger network, called Artificial Neural Networks...</p><div class='article__bottom'><div class='article-tags__box'><a href='/tag/machine learning' class='article__tag'>machine learning</a><a href='/tag/neural networks' class='article__tag'>neural networks</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "machine learning and neural networks",
      "url"      : "/a-quick-introduction-to-artificial-neural-networks-part-1",
      "date"     : "2018-04-09 16:01:35 +0100",
      "content"  : "Update: Since 2018 I have created better resources for those interested in machine learning. Head over to this course on mahcine learning which covers neural networks.Artificial Neural NetworksArtificial neurons mimic the basic function of biological neurons, and much like their biological counterparts they only become useful when connected in a larger network, called Artificial Neural Networks.Neural networks are extremely adept at recognising patterns, this is pattern recognition is the reason they have become so widely used and talked about in recent years. The ability of neural networks to discover and recognise patterns allows them to far surpass traditional methods in computer science, making them viable for use in research and business.An Artificial NeuronThe image below show an illustration of a single biological neuron annotated to describe a single artificial neurons function.A biological neuron receives input signals from its dendrites from other neurons and sends output signals along its axon, which branches out and connects to other neurons. In the illustration above, the input signal is represented by x0, as this signal ‘travels’ it is multiplied (w0 x0) based on the a weight variable (w0). The weight variables are learnable and the weights strength and polarity (positive or negative) control the influence of the signal. The influence is determined by summing the signal input and weight (∑i wi xi + b) which is then calculated by the activation function f, if it is above a certain threshold the neuron fires.Activation Functions in BriefThe frequency of the firing of an artificial neuron is determined by an activation function. It determines at what threshold the neuron will fire. This section describes the Sigmoid activation function to bring clarity to the operation of an artificial neuron. Activation functions will be discussed in detail further on in this guide.The graph above shows the Sigmoid activation function, which will convert all input signals into positive values between 0 and 1. The use of other activation functions with wider values, or negative values change the frequency of the firing of a neuron and will suit different types of data and purposes.Activation functions are dicussed in further detail in the final quick introduction post, part two."
    } ,
  
    {
      "title"    : "The C Programming Language (Book Review)",
      "article"  : "<div class='article col col-12 animate'> <div class='article__inner'> <div class='article__content'> <h2 class='article__title'> <a href='/the-c-programming-language-book-review'>The C Programming Language (Book Review)<i class='ion ion-md-arrow-round-forward'></i></a> </h2> <div class='article__meta'> <time class='article__date' datetime='2018-03-17T16:52:00+00:00'>17 March 2018</time> – <span class='article__minutes'>4min read</span> </div><p class='article__excerpt'>In its fifty-second printing the book is a classic computer science text. It is revered among computer scientists because Dennis Ritchie, the creator of C, is one of the authors...</p><div class='article__bottom'><div class='article-tags__box'><a href='/tag/books' class='article__tag'>books</a><a href='/tag/reviews' class='article__tag'>reviews</a><a href='/tag/c' class='article__tag'>c</a></div></div></div></div></div>",
      "category" : "",
      "tags"     : "books, reviews, and c",
      "url"      : "/the-c-programming-language-book-review",
      "date"     : "2018-03-17 16:52:00 +0000",
      "content"  : "Brian W. Kernighan, Dennis M. Ritchie. The C Programming Language. 2nd Edition. Upper Saddle River, NJ, USA: Prentice-Hall, Inc. 2014. ISBN 0-13-110362-8, 0-13-110370-9. GBP£49 / USD$63  “This book was typeset in Times New Roman and Courier by the authors, using an Autologic APS-5 phototypesetter and a DEC VAX 8550 running the 9th Edition of the UNIX operating system.”This is the proclamation on the copyright page of ‘The C Programming Book’. It crosses my mind I am writing this review on a Mac running OS X, a distant child of the 9th Edition of UNIX thirty-seven years later.IntroductionIn its fifty-second printing the book is a classic computer science text. It is so revered among computer scientists because the original creator of C, Dennis Ritchie, is one of the authors. ‘The C Programming Language’ aims to teach beginner’s the C programming language from scratch via a quick “Tutorial introduction” and a series of example programs exploring various facets of the language in increasing difficulty.The second edition, and the most recent, was first printed in 1989 to include the various changes and additions after the American National Standards Institute (ANSI) and the International Organisation for Standardisation (ISO) created the C89/C90 standards, which for standardised the language for the first time. Despite being in its fifty-seventh printing, it hasn’t been updated in twenty-seven years, and as a result it is starting to show its age – if only in it use of language.‘The C Programming Language’ is noticeably ‘stuffy’ and verbose. At times it approaches a technical manual to my modern eyes. However, if this is the only major weakness, it can be overlooked due to the books status and relevant content. Yet, despite my nostalgia and reverence for ‘The C Programming Language’ I would argue there are much better books to learn C.ComparisonWhen compared to modern texts such as ‘Learning C the Hard Way’, ‘The C Programming Language’ immediately looks wrinkled. This comparison is particularly apt as they each teach C in a similar way – through practical, increasingly difficult programming examples. In ‘Learn C the Hard Way’ succinct, lively, but professionally written chapters replace the verbose, stuffy language of ‘The C Programming Language’. In ’Learn C the Hard Way’ each chapter sets out a programming task centred around a language feature, each task builds a real-world program. While the authors of ‘The C Programming Language’, state “we have tried where possible to show useful programming techniques”, and “when forced to make a decision [on what to include], we have concentrated on the language”. This is not unreasonable, yet, ‘Learn C the Hard Way’ manages to create real-world “complete programs” and show off features of the language at the same time.Regardless of the criticism of the language of ‘The C Programming Language’ is unsurpassed as a technical reference. And despite its stuffiness and verbosity it does a good job of guiding the reader through aspects of the language. The authors concentration on the language is clear, and the result is a perfectly usable, but inferior to modern texts, introduction to C.ContentsThe book starts with ‘Chapter 1: Tutorial Introduction’, a 34 page, fast-paced, practical introduction to the language which encourages readers to write “complete programs” using the major features of C. This format is useful to the reader because they have gained some practical knowledge, so when they read the detailed sections which deal with those features they are more likely to understand the explanation. The book assumes the reader already has some basic programming knowledge, of compilation and algebraic expressions.Chapters 2 through 6 cover those features, and others, in greater detail. The chapters keep the focus on writing “complete programs”, as opposed to code snippets, which arguably leads to greater usefulness and comprehension for the reader. Chapter 7 describes the standard library, Chapter 8 deals with the interface between C programs and the UNIX operating system, and the final section, Appendix A, contains a reference manual.Final Thoughts’The C Programming Language’ is still a useful book to learn the C language, however let us not be held back by nostalgia and unmoving reverence. The book holds up surprisingly well for a twenty-seven-year-old revision of a thirty-seven-year-old book (its original printing). I argue if you are to buy only one book to learn C, don’t spend £33 on ‘The C Programming Language’. Consider ‘Learn C the Hard Way’, or another modern text. Have a look at some of the free PDF books which have gained popularity such as ‘Modern C’ from Prof. Jens Gustedt, a French academic and ISO expert in C.‘The C Programming Language’ can have a place on your bookshelf, but only among other C programming books."
    } 
  
]
